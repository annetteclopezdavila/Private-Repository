# -*- coding: utf-8 -*-
"""DNN_BEST

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sjDSIPvThwwFkjvcPEHzuJe3iYNpCAI_
"""

#import Google Drive
from google.colab import drive
drive.mount('/content/gdrive')

#IMPORTS
import tensorflow as tf
import numpy as np
import glob
import re
from PIL import Image
from tensorflow.keras.optimizers import RMSprop
# Use some functions from tensorflow_docs
!pip install -q git+https://github.com/tensorflow/docs
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

#Train Files
train_files = glob.glob('/content/gdrive/My Drive/train_data2/*.jpeg')
train_files

train_files.sort(key=lambda f: int(re.sub('\D', '', f)))
train_imgs = np.array([np.array(Image.open(fname)) for fname in train_files])

labels = np.genfromtxt('/content/gdrive/My Drive/labels.csv', delimiter=',')
train_labs = labels[1:101, 1]

#Test Files
test_files = glob.glob('/content/gdrive/My Drive/test_data2/*.jpeg')
test_files

test_files.sort(key=lambda f: int(re.sub('\D', '', f)))
test_imgs = np.array([np.array(Image.open(fname)) for fname in test_files])

test_labs = labels[101:131, 1]

train_imgs  = train_imgs / 255.0
test_imgs = test_imgs / 255.0

def build_model():
  model = tf.keras.models.Sequential([                         
    tf.keras.layers.Flatten(),
    #tf.keras.layers.Dense(512,  activation='relu')
    tf.keras.layers.Dense(128,  activation='relu'),    
    tf.keras.layers.Dense(64, activation=tf.nn.softmax),
    tf.keras.layers.Dense(1)
  ])
  return model

optimizer = tf.keras.optimizers.RMSprop(0.001)
model.compile(optimizer = optimizer,
              loss = 'mse',
              metrics=['mse', 'mae', 'acc'])

history= model.fit(train_imgs, train_labs, epochs=500, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

import pandas as pd
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
last=hist.tail()
last

head=hist.head()
head

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.image  as mpimg
import matplotlib.pyplot as plt

acc=history.history['acc']
val_acc=history.history['val_acc']
loss=history.history['loss']
val_loss=history.history['val_loss']
mae=history.history['mae']
mse=history.history['mse']
#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
epochs=range(len(acc)) # Get number of epochs

plt.plot(epochs, hist['mse'], 'r', "MSE")
plt.title('MSE')
plt.axis([495, 500, 556, 560])
plt.figure()

plt.plot(epochs, mae, 'b', "MAE")
plt.title('MAE')
plt.axis([0, 500, 18, 24])
plt.legend()
plt.figure()


#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot(epochs, loss, 'r', "Training Loss")
plt.plot(epochs, val_loss, 'b', "Validation Loss")
#plt.axis([0, 4, 1619, 1625])
plt.legend()
plt.figure()

loss, mse, mae, acc=model.evaluate(test_imgs, test_labs)

error = test_predictions - test_labs
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")